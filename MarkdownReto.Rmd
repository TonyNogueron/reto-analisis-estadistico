---
title: "Analisis"
author: "Paulina Galindo, Antonio Noguerón, Pamela Ruíz"
date: "6/1/2022"
output: html_document
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyr)
library(readr)
library(skimr)
library(readxl)
library(ggplot2)
library(corrplot)
library(GGally)
library(psych)
library(Hmisc)
library(car)
library(olsrr)
historico <- read_excel("Datos_Situacion_Problema.xlsx", sheet="Histórico de defectos")
muestreo <- read_excel("Datos_Situacion_Problema.xlsx", sheet="Datos de muestreo", skip=1)
indice <- read_excel("Datos_Situacion_Problema.xlsx", sheet="Índice")

head(muestreo)
str(muestreo)
resumen <- summary(muestreo)
colnames <- names(muestreo)
num_datos <- nrow(muestreo)
```

# Introducción a la situación problema

Usted trabaja en una empresa que se dedica a la producción de piezas automotrices a base de Polipropileno. Debido a cuestiones personales, el técnico experto en el proceso de extrusión salió de la empresa y el porcentaje de defectos está por los cielos.

Es necesario determinar las variables importantes para el proceso de extrusión de Polipropileno en una máquina de tornillo sencillo para poder mejorar la producción. Es de particular interés el porcentaje de producto defectuoso. Cada producto es inspeccionado visualmente por personal del departamento de calidad. Para esto, cada cierto tiempo se toman muestras de producto final y se determina si éste tiene algún defecto. Una vez inspeccionado cada producto, se clasifica como defectuoso o no defectuoso y se calcula un cociente entre los defectuosos y el total producido para determinar el porcentaje de producto defectuoso.

La máquina de extrusión que se utiliza en el proceso es una Welex y de acuerdo con su información técnica, hay *9 variables que podrían afectar la calidad del producto*, tal y como se muestra en la tabla siguiente:
  
  | FACTOR | NOMBRE DE LA VARIABLE |
  | :----: | :----: |
  |A|Presión bomba|
  |B|Temperatura plástico 3(bomba)|
  |C|Temperatura plástico 4(mezcladora)|
  |D|Temperatura tornillo (usillo)|
  |E|RPM tornillo (usillo)|
  |F|Temperatura barril|
  |G|Velocidad extrusión|
  |H|Temperatura enfriadores|
  |I|Tipo materia prima|
  
  ## Para empezar nuestro análisis renombramos las variables
  
```{r}
attach(muestreo)
#        NUEVO                 # ANTERIOR
datos<- rename(muestreo, PresionBomba = A,
               TempPlastico3Bomba  = B,
               TempPlastico4Mezcladora = C,
               TempTornilloUsillo = D,
               RpmTornilloUsillo = E,
               TempBarril = F,
               VelocidadExtrusion = G,
               TempEnfriadores = H,
               TipoMateria = I,
               PorcentajeDefectos = Y
)

names(datos)
attach(datos)

```
## Seguido de esto graficamos cada variable respecto al porcentaje de error
```{r}
plot(A, Y, main="Gráfica presión v.s. porcentaje de defectos", xlab="Presión", ylab="Defectos %")
plot(B, Y, main="Gráfica temp plástico 3 v.s. porcentaje de defectos", xlab="Temp plástico 3", ylab="Defectos %")
plot(C, Y, main="Gráfica temp plástico 4 v.s. porcentaje de defectos", xlab="Temp plástico 4", ylab="Defectos %")
plot(D, Y, main="Gráfica temp tornillo v.s. porcentaje de defectos", xlab="Temp tornillo", ylab="Defectos %")
plot(E, Y, main="Gráfica RPM v.s. porcentaje de defectos", xlab="RPM", ylab="Defectos %")
plot(F, Y, main="Gráfica temp barril v.s. porcentaje de defectos", xlab="Temp barril", ylab="Defectos %")
plot(G, Y, main="Gráfica velocidad v.s. porcentaje de defectos", xlab="Velocidad", ylab="Defectos %")
plot(H, Y, main="Gráfica temp enfriadores v.s. porcentaje de defectos", xlab="Temp enfriadores", ylab="Defectos %")
plot(I, Y, main="Gráfica materia prima v.s. porcentaje de defectos", xlab="Materia prima", ylab="Defectos %")

```

## Creamos el histograma

Para encontrar el mejor modelo de regresión lineal, primero debemos determinar si la distribución de los datos en cada variable es normal. Esta distribución nos ayudará a comprobar la linealidad y la validez de usar estos datos en el modelo.

Para observar la distribución de los datos graficaremos cada variable excepto la variable I que representa el tipo de material porque esta es una variable cualitativa que representa los 3 tipos de materiales.
Gracias a que esta variable es cualitativa, nuestros datos se dividen en 3 grupos, uno por cada material.


```{r}
multi.hist(x = muestreo, dcol = c("blue", "red"),
           dlty = c("dotted","solid"), lwd = c(2,1),
           main = c("A", "B", "C", "D", "E", "F", "G", "H", "Y"))
```


## Después obtuvimos el correlograma para poder obtener un análisis más visual de la  correlación entre las variables.
Al ver el correlograma, vimos que la velocidad de extrusión y la Presión de la bomba están relacionadas.
```{r}
corrplot(cor(datos))
```
## Creamos la gráfica de pares: 

```{r}
ggpairs(datos)

```

## Graficamos las variables entre ellas

```{r}
plot(PresionBomba, VelocidadExtrusion, main="Gráfica Presión de la Bomba \n v.s. Velocidad de extrusión", xlab="Presión de la Bomba [Bar]", ylab="Velocidad Extrusión [m/s]")
plot(TempPlastico4Mezcladora, PorcentajeDefectos, main="Gráfica de Temperatura de Plástico 4 (mezcladora) \n v.s. Porcentaje de Defectos", xlab="Temperatura Plástico 4 [°C]", ylab="Defectos [%]")
plot(TempPlastico3Bomba, PorcentajeDefectos, main="Gráfica de Temperatura de Plástico 3 (bomba) \n v.s. Porcentaje de Defectos", xlab="Temperatura Plástico 3 [°C]", ylab="Defectos [%]")
plot(TempBarril, PorcentajeDefectos, main="Gráfica de Temperatura del Barril \n v.s. Porcentaje de Defectos", xlab="Temperatura del Barril [°C]", ylab="Defectos [%]")
```

## Obtuvimos la regresión lineal simple con una de las variables con mayor correlación

```{r}
regresionSimple <- lm(Y ~ C, data=muestreo)
summary(regresionSimple)
```

## Analizamos la regresión lineal múltiple:

Para encontrar el mejor modelo de regresión lineal haremos varios modelos en donde haremos pruebas de hipótesis para ir eliminando las variables que no son significativas.

Primero haremos un modelo de regresión para todo el conjunto de datos, pero como hay 3 tipos de materiales distintos, dividiremos nuestro conjunto de datos en 3 y realizaremos un modelo de regresión múltiple para cada conjunto de datos filtrado por material.


### Regresión lineal de todas las variables
```{r}
regresion <- lm(Y ~ A + B + C + D + E + F + G + H + I, data=muestreo)
summary(regresion)
```
El modelo con todas las variables introducidas como predictores, tiene un R de 0.7237, lo que nos indica que es capaz de explicar el 72.37% de la variabilidad observada en el porcentaje de defectos.
Después de hacer las pruebas de hipótesis podemos concluir que en las variables G (velocidad extrusión), H (temperatura enfriadores), I (tipo de material) no se rechaza la hipótesis nula; por ende, no se eliminarán del modelo.


Además, es necesario eliminar la variable G (velocidad extrusión) porque tiene un coeficiente de correlación de 0.859 con la variable A (presión bomba). Esto significa que están fuertemente relacionadas y para que un modelo de regresión múltiple sea correcto, es necesario que las variables sean independientes entre si; si no, una de las variables debe eliminarse.

## Regresión lineal con las variables que tiene un valor p < 0.05
#### Regresión lineal eliminando:
- Velocidad de extrusión
- Temperatura de los enfriadores
- Tipo de materia

```{r}
regresion1 <- lm(Y ~ A + B + C + D + E + F, data=muestreo)
summary(regresion1)
```

El modelo sin las variables mencionadas anteriormente, tiene un R de 0.7293, lo que nos indica que es capaz de explicar el 72.93% de la variabilidad observada en el porcentaje de defectos. Después de realizar las pruebas de hipótesis podemos concluir que en todas las variables se rechaza la hipótesis nula y este es el mejor modelo.

Para poder confirmar que el modelo escogido es el mejor, usamos la función step de R Studio que realiza todos los modelos de regresión múltiple, hace la comparación del valor AIC y regresa la fórmula del mejor modelo.


# Comprobación del modelo de regresión múltiple

```{r}
step(object = regresion, direction = "both", trace = 1)

```

Elegimos el modelo con menor AIC.

```{r}
 bestLm <- lm(formula = Y ~ A + B + C + D + E + F, data = muestreo)

summary(bestLm)

```


## Interpretación del modelo elegido

El modelo tiene un R^2 de 0.7293, por lo que es capaz de explicar el 72.93% de la variabilidad observada en el porcentaje de defectos.

```{r}
plot(bestLm)
```

### Análisis de la gráfica residuos vs valores ajustados

Los datos 91, 45 y 13 presentan diferencias mayores, por lo que podrían tener algún problema.


### Análisis de la gráfica normalidad de residuos

Los datos 91, 45 y 13 se alejan de la normalidad.


### Análisis de la gráfica localización-escala

Los datos 91, 45 y 13 al aparecer por tercera vez nos indican que deberíamos analizar con más detalle para ubicar un posible problema.


### Análisis de la gráfica residuos vs leverage

Todos los residuos se encuentran dentro de la distancia de Cook, así que no hay problema.



## Modelo de predicción

```{r}
datos_nuevos <- data.frame(A=73,B=213,C=220,D=195,E=110,F=130,G=4.5,H=70,I=2)
predict(regresion1, datos_nuevos)
```



## Modelos de regresión múltiple por cada tipo de material

Para poder crear tres modelos de regresión múltiple para cada tipo de material, debemos filtrar los datos originales para crear tres dataframes que representen los datos obtenidos al usar cierto tipo de material.


```{r}
Tipo1 <- filter(muestreo, I == 1)



```







----------------------------------------------------------------------------
# REVISAR!!!!!!






# Multicolinealidad

```{r}
rcorr(as.matrix(muestreo))
```

```{r}
corrplot(cor(muestreo))
```


## Tolerancia  y Factor de Inflación de la Varianza del mejor modelo

```{r}
vif(bestLm)

```

```{r}
tol <- 1/vif(bestLm)
tol
```

Las covariables están relacionadas entre sí y su tolerancia no está debajo de 0.2 no indica que haya un problema serio.

# Identificación de valores atípicos o influyentes en la regresión

Análisis de las variables por separado.

```{r}
boxplot.matrix(as.matrix(muestreo),use.cols = T)
```


# Detección de influyentes
*** revisar
```{r}
i <- nrow(bestLm)
abs(dfbeta(bestLm))>sqrt(2/i)
```

Identificación de observaciones que son potencialmente influyentes.

```{r}
summary(influence.measures(bestLm))

```
```{r}
influencePlot(bestLm)
```

Los círculos nos ayudan a detectar las observaciones influyentes y el tamaño de los círculos denota la intensidad de su influencia.

Analizando la gráfica podemos observar que los datos 91, 30, 40 y 13 tienen mayor influencia que el resto de estos; además al tener un mayor tamaño son datos a los que debemos tener mayor cuidado.


# Análisis de observaciones atípicas

```{r}
ols_plot_cooksd_bar(bestLm)

```

# Análisis de serie de tiempo

```{r}
str(historico)

productoA = ts(historico$`Producto A`, start = 1, frequency = 12)
productoB = ts(historico$`Producto B`, start = 1, frequency = 12)
productoC = ts(historico$`Producto C`, start = 1, frequency = 12)
print(productoA)
print(productoB)
print(productoC)
#boxplot(productoA~ cycle(productoA)) #  non-numeric argument to binary operator
cycle(productoA)
cycle(productoB)
cycle(productoC)

#productoA.ts.desc = decompose(productoA)
#productoB.ts.desc = decompose(productoB)
#productoC.ts.desc = decompose(productoC)


```















